from flask import Flask, request, send_file, jsonify
from diffusers import StableDiffusionPipeline, StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionInpaintPipeline
from controlnet_aux import OpenposeDetector
import torch
import os
import requests
from PIL import Image
from io import BytesIO
import threading
from pyngrok import ngrok

# Flask ì•± ì„¤ì •
app = Flask(__name__)
device = "cuda" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float32

HF_TOKEN = os.getenv("HUGGINGFACE_HUB_TOKEN")

print("ëª¨ë¸ ë¡œë“œ ì‹œì‘...")

# 1. í¬ì¦ˆ ì œì–´ìš© ControlNet ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ (OpenPose)
controlnet_pose = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-openpose",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_pose = StableDiffusionControlNetPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    controlnet=controlnet_pose,
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_pose.safety_checker = None
pipe_pose.to(device)

# 2. êµ¬ë„ ì œì–´ìš© ControlNet ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ (Depth)
controlnet_depth = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-depth",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_depth = StableDiffusionControlNetPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    controlnet=controlnet_depth,
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_depth.safety_checker = None
pipe_depth.to(device)

# 3. ìºë¦­í„° ìŠ¤íƒ€ì¼ìš© íŒŒì´í”„ë¼ì¸ (ê¸°ë³¸ ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼)
pipe_style = StableDiffusionPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_style.safety_checker = None
pipe_style.to(device)

# 4. ë°°ê²½ ìƒì„±ìš© íŒŒì´í”„ë¼ì¸
pipe_bg = StableDiffusionPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_bg.safety_checker = None
pipe_bg.to(device)

# 5. ì–¼êµ´ ë””í…Œì¼ ë³´ì •ìš© Inpainting íŒŒì´í”„ë¼ì¸
pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_inpaint.safety_checker = None
pipe_inpaint.to(device)

# 6. ì˜¤ë¸Œì íŠ¸ ì¶”ê°€ìš© ControlNet ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ (Canny)
controlnet_canny = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_canny = StableDiffusionControlNetPipeline.from_pretrained(
    "nitrosocke/Ghibli-Diffusion",
    controlnet=controlnet_canny,
    use_auth_token=HF_TOKEN,
    torch_dtype=torch_dtype
)
pipe_canny.safety_checker = None
pipe_canny.to(device)

print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

def save_image(image, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    image.save(path)
    print(f"ì´ë¯¸ì§€ ì €ì¥: {path}")

@app.route('/generate-scene', methods=['POST'])
def generate_scene():
    try:
        # 1. í¬ì¦ˆ ì´ë¯¸ì§€ URL ë°›ê¸°
        pose_image_url = request.json.get('pose_image_url', '')
        if not pose_image_url:
            return jsonify({'error': 'pose_image_url required'}), 400

        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(pose_image_url)
        pose_image = Image.open(BytesIO(response.content)).convert("RGB")
        
        # OpenPoseë¡œ í¬ì¦ˆ ì¶”ì¶œ
        pose_detector = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')
        pose_map = pose_detector(pose_image)
        
        # 2. í¬ì¦ˆ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±
        result = pipe_pose(
            prompt="a character in Ghibli style",
            image=pose_map,
            num_inference_steps=30
        )
        current_image = result.images[0]

        # 3. êµ¬ë„ ì œì–´ ì ìš©
        depth_prompt = request.json.get('depth_prompt', '')
        if depth_prompt:
            result = pipe_depth(
                prompt=depth_prompt,
                image=current_image,
                num_inference_steps=30
            )
            current_image = result.images[0]

        # 4. ìŠ¤íƒ€ì¼ ì ìš©
        style_prompt = request.json.get('style_prompt', '')
        if style_prompt:
            result = pipe_style(
                prompt=style_prompt,
                image=current_image,
                num_inference_steps=30
            )
            current_image = result.images[0]

        # 5. ë°°ê²½ ìƒì„±
        bg_prompt = request.json.get('bg_prompt', '')
        if bg_prompt:
            result = pipe_bg(
                prompt=bg_prompt,
                image=current_image,
                num_inference_steps=30
            )
            current_image = result.images[0]

        # 6. ì–¼êµ´ ë””í…Œì¼ ë³´ì •
        face_mask = request.files.get('face_mask')
        detail_prompt = request.json.get('detail_prompt', '')
        if face_mask and detail_prompt:
            mask_image = Image.open(face_mask).convert("L")
            result = pipe_inpaint(
                prompt=detail_prompt,
                image=current_image,
                mask_image=mask_image,
                num_inference_steps=30
            )
            current_image = result.images[0]

        # 7. ì˜¤ë¸Œì íŠ¸ ì¶”ê°€
        object_prompt = request.json.get('object_prompt', '')
        if object_prompt:
            result = pipe_canny(
                prompt=object_prompt,
                image=current_image,
                num_inference_steps=30
            )
            current_image = result.images[0]

        # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥
        path = "static/images/final_scene.png"
        save_image(current_image, path)
        return send_file(path, mimetype='image/png')

    except Exception as e:
        return jsonify({'error': str(e)}), 500

def prompt_scene_input():
    print("\nğŸ¬ AI ì›¹íˆ° ì”¬ ìƒì„± íŒŒì´í”„ë¼ì¸")
    
    # 1. í¬ì¦ˆ ì´ë¯¸ì§€ URL ì…ë ¥
    pose_image_url = input("ğŸ–¼ï¸ í¬ì¦ˆ ì´ë¯¸ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”: ")
    if not pose_image_url:
        print("â— í¬ì¦ˆ ì´ë¯¸ì§€ URLì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
        return

    # 2. êµ¬ë„ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    depth_prompt = input("ğŸ¥ êµ¬ë„ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")

    # 3. ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    style_prompt = input("ğŸ¨ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")

    # 4. ë°°ê²½ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    bg_prompt = input("ğŸ–¼ï¸ ë°°ê²½ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")

    # 5. ì–¼êµ´ ë§ˆìŠ¤í¬ ë° ë””í…Œì¼ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    face_mask_path = input("ğŸ˜· ì–¼êµ´ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")
    detail_prompt = input("ğŸ‘¤ ë””í…Œì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")

    # 6. ì˜¤ë¸Œì íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥
    object_prompt = input("ğŸ ì˜¤ë¸Œì íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")

    try:
        # API ìš”ì²­ ë°ì´í„° ì¤€ë¹„
        data = {
            "pose_image_url": pose_image_url,
            "depth_prompt": depth_prompt,
            "style_prompt": style_prompt,
            "bg_prompt": bg_prompt,
            "detail_prompt": detail_prompt,
            "object_prompt": object_prompt
        }

        # íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        files = {}
        if face_mask_path:
            files['face_mask'] = open(face_mask_path, 'rb')

        # API í˜¸ì¶œ
        response = requests.post('http://127.0.0.1:5000/generate-scene', 
                               json=data, 
                               files=files if files else None)

        if response.status_code == 200:
            print("âœ… ì”¬ ìƒì„± ì™„ë£Œ!")
            with open("static/images/final_scene.png", "wb") as f:
                f.write(response.content)
            print("ğŸ‰ ìµœì¢… ì´ë¯¸ì§€ê°€ static/images/final_scene.png ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {response.text}")

    except Exception as e:
        print(f"âŒ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        # ì—´ë¦° íŒŒì¼ ë‹«ê¸°
        if 'files' in locals() and files:
            for file in files.values():
                file.close()

def run_cli():
    while True:
        print("\n1. ì”¬ ìƒì„± ì‹œì‘")
        print("0. ì¢…ë£Œ")
        
        choice = input("\nì›í•˜ëŠ” ì‘ì—… ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        if choice == "1":
            prompt_scene_input()
        elif choice == "0":
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("â— ìœ íš¨í•œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (0-1).")

def run_flask():
    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)

if __name__ == '__main__':
    # ngrok ì„¤ì •
    from pyngrok import conf
    conf.get_default().auth_token = "2w7VRYBj2DCgHZqi8pCXh0DyFrr_3SfpgoXUWGkDyeejAw2RY"
    
    # ngrokì„ í†µí•´ Flask ì„œë²„ë¥¼ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
    public_url = ngrok.connect(5000)
    print("Flask ì„œë²„ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì ‘ê·¼ URL:", public_url)

    # Flask ì„œë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    flask_thread = threading.Thread(target=run_flask)
    flask_thread.start()

    # CLI ì‹¤í–‰
    run_cli() 