!pip install flask flask-cors openai diffusers transformers accelerate safetensors opencv-python requests pyngrok controlnet_aux fastapi uvicorn nest-asyncio pydantic

# ğŸ“Œ import
import torch, gc, base64, requests, os, time
from io import BytesIO
from PIL import Image
from flask import Flask, request, jsonify
from flask_cors import CORS
from threading import Thread
from concurrent.futures import ThreadPoolExecutor
import asyncio
from pyngrok import ngrok, conf
from openai import OpenAI
from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionControlNetPipeline,
    ControlNetModel
)
from controlnet_aux.open_pose import OpenposeDetector
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ğŸ“Œ í™˜ê²½ ì„¤ì •
def initialize_tokens(hf_token: str, openai_key: str, ngrok_token: str):
    global HF_TOKEN, OPENAI_API_KEY, client, pipe_style, pipe_final
    
    # í† í° ì„¤ì •
    HF_TOKEN = hf_token
    OPENAI_API_KEY = openai_key
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # ngrok í† í° ì„¤ì •
    conf.get_default().auth_token = ngrok_token
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    pipe_style = StableDiffusionPipeline.from_pretrained(
        "nitrosocke/Ghibli-Diffusion", token=HF_TOKEN, torch_dtype=torch_dtype
    ).to(device)
    pipe_style.safety_checker = None
    
    detector = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")
    
    controlnet = ControlNetModel.from_pretrained(
        "lllyasviel/sd-controlnet-openpose", token=HF_TOKEN, torch_dtype=torch_dtype
    )
    pipe_final = StableDiffusionControlNetPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5", controlnet=controlnet, token=HF_TOKEN, torch_dtype=torch_dtype
    ).to(device)
    pipe_final.safety_checker = None

# âœ¨ Flask app
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MBë¡œ ì œí•œ ì¦ê°€
CORS(app)

# FastAPI ì•± ì„¤ì •
app = FastAPI(title="Ghibli Image Generator API")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic ëª¨ë¸
class GenerateRequest(BaseModel):
    user_id: str
    diary: str
    gender: str
    node_server_url: str

# âœ¨ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def get_prompts_from_chatgpt(user_diary: str, gender: str):
    system_prompt = (
        "You are an AI assistant that creates AI art prompts in Ghibli style from a diary entry.\n\n"
        "Your task is to read the diary and extract the most emotionally or visually important moment as a single scene.\n"
        "Then, generate two prompts:\n\n"
        "1. pose_prompt:\n"
        "- Describe the character's full-body pose, composition, placement, and interactions with important elements in the scene (e.g., a cat, a window, a book).\n"
        "- Use keywords like pastel tone, monotone background, natural posture, and always include 'Ghibli style'.\n"
        "- Format should be a list of keywords or short phrases separated by commas (not a complete sentence).\n"
        "- The total token count must not exceed 75 tokens.\n"
        "- This prompt is used for pose estimation.\n\n"
        "2. full_prompt:\n"
        "- Start with a short pose description (e.g., dancing pose).\n"
        "- Then add keywords or short phrases (comma-separated) describing the following:\n"
        "  - clothing style (e.g., casual dress, school uniform)\n"
        "  - background environment (e.g., grassy field, cozy room, forest path)\n"
        "  - facial expression (e.g., gentle smile, curious look)\n"
        "  - eye details (e.g., sparkling eyes, soft gaze)\n"
        "  - interaction with other elements (e.g., reaching toward cat)\n"
        "  - atmosphere (e.g., peaceful, nostalgic, dreamy)\n"
        "  - artistic style and texture (e.g., watercolor painting, skin glow, sunlight filtering)\n"
        "- Always include 'Ghibli style'.\n"
        "- Format should also be a comma-separated list of keywords or short phrases (not a complete sentence).\n"
        "- The total token count must not exceed 75 tokens.\n\n"
        "Both prompts must be in fluent English and formatted as follows:\n"
        "pose_prompt: ...\n"
        "full_prompt: ...\n"
    )

    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Here is the diary:\n{user_diary}\nGender: {gender}"}
        ],
        temperature=0.8
    )
    content = res.choices[0].message.content
    lines = content.split("\n")
    pose_prompt = next((l.split(":", 1)[1].strip() for l in lines if l.lower().startswith("pose_prompt")), "")
    full_prompt = next((l.split(":", 1)[1].strip() for l in lines if l.lower().startswith("full_prompt")), "")
    return pose_prompt, full_prompt

# âœ¨ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
def generate_image(pose_prompt: str, full_prompt: str):
    pose_img = pipe_style(prompt=pose_prompt, num_inference_steps=20).images[0]
    pose_map = detector(pose_img).convert("L").convert("RGB")
    result_img = pipe_final(prompt=full_prompt, image=pose_map, num_inference_steps=30).images[0]

    torch.cuda.empty_cache()
    gc.collect()

    return result_img

# âœ¨ ì´ë¯¸ì§€ -> base64
def image_to_base64(img: Image.Image) -> str:
    buffer = BytesIO()
    img.save(buffer, format="PNG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")

@app.post("/generate")
async def generate(request: GenerateRequest):
    try:
        print("ğŸ”¥ [SERVER] /generate ìš”ì²­ ë“¤ì–´ì˜´!")
        print(f"ğŸ‘¤ user_id: {request.user_id}")
        print(f"ğŸ“ gender: {request.gender}")
        print(f"ğŸ“” diary ë‚´ìš© (ì•ë¶€ë¶„): {request.diary[:100]}...")
        print(f"ğŸŒ Node.js ì„œë²„ URL: {request.node_server_url}")

        # ChatGPT í”„ë¡¬í”„íŠ¸ ìƒì„±
        pose_prompt, full_prompt = get_prompts_from_chatgpt(request.diary, request.gender)
        print("âœ¨ pose_prompt:", pose_prompt)
        print("âœ¨ full_prompt:", full_prompt)

        # ì´ë¯¸ì§€ ìƒì„±
        result_img = generate_image(pose_prompt, full_prompt)
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")

        # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        img_byte_arr = BytesIO()
        result_img.save(img_byte_arr, format='PNG')
        img_bytes = img_byte_arr.getvalue()
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë³€í™˜ ì™„ë£Œ!")

        try:
            # Node.js ì„œë²„ë¡œ ì´ë¯¸ì§€ ì „ì†¡
            response = requests.post(
                request.node_server_url,
                data=img_bytes,
                headers={
                    'Content-Type': 'image/png'
                }
            )

            if response.status_code == 200:
                return {
                    "success": True,
                    "message": "ì´ë¯¸ì§€ ìƒì„± ë° ì „ì†¡ ì„±ê³µ"
                }
            else:
                print(f"âŒ Node.js ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                print(f"âŒ ì‘ë‹µ ë‚´ìš©: {response.text}")
                return {
                    "success": False,
                    "message": "Node.js ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜",
                    "error": response.text
                }

        except requests.exceptions.RequestException as e:
            print(f"âŒ Node.js ì„œë²„ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "message": "Node.js ì„œë²„ ì—°ê²° ì‹¤íŒ¨",
                "error": str(e)
            }

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return {
            "success": False,
            "message": "ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "error": str(e)
        }

if __name__ == "__main__":
    import nest_asyncio
    import uvicorn
    from pyngrok import ngrok, conf

    # Colabì˜ ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ í•´ê²°
    nest_asyncio.apply()

    # í† í° ì´ˆê¸°í™” (ì™¸ë¶€ì—ì„œ ë°›ì•„ì˜¨ í† í°ë“¤)
    initialize_tokens(
        hf_token="your_huggingface_token",
        openai_key="your_openai_key",
        ngrok_token="your_ngrok_token"
    )

    # ngrok ì—°ê²°
    public_url = ngrok.connect(8005)
    print("ğŸš€ ngrok URL:", public_url)

    # ì„œë²„ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¶”ê°€)
    uvicorn.run(app, host="0.0.0.0", port=8005, timeout_keep_alive=120)